{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/introduction-to-web-scraping-with-beautifulsoup-e87a06c2b857\n",
    "\n",
    "Target article -> https://en.wikipedia.org/wiki/Artificial_intelligence\n",
    "\n",
    "Scrapy is a complete web scraping framework which takes care of everything from getting the HTML, to processing the data. Selenium is a browser automation tool that can for example enable you to navigate between multiple pages. These two libraries have a steeper learning curve than Request which is used to get HTML data and BeautifulSoup which is used as a parser for the HTML.\n",
    "\n",
    "In this post we will scrap the “content” and “see also” sections from an arbitrary Wikipedia article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Artificial_intelligence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = urllib.request.urlopen(url) # conntect to website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start parsing the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial intelligence - Wikipedia'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find specific elements in the page\n",
    "The created BeautifulSoup object can now be used to find elements in the HTML. When we inspected the website we saw that every list item in the content section has a class that starts with `tocsection-` and we can us BeautifulSoup’s find_all method to find all list items with that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile('^tocsection-')\n",
    "content_lis = soup.find_all('li', attrs={'class': regex})\n",
    "print(len(content_lis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the raw text we can loop through the array and call the `getText` method on each list item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "for li in content_lis:\n",
    "    content.append(li.getText().split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 History',\n",
       " '2 Basics',\n",
       " '3 Problems',\n",
       " '3.1 Reasoning, problem solving',\n",
       " '3.2 Knowledge representation',\n",
       " '3.3 Planning',\n",
       " '3.4 Learning',\n",
       " '3.5 Natural language processing',\n",
       " '3.6 Perception',\n",
       " '3.7 Motion and manipulation',\n",
       " '3.8 Social intelligence',\n",
       " '3.9 General intelligence',\n",
       " '4 Approaches',\n",
       " '4.1 Cybernetics and brain simulation',\n",
       " '4.2 Symbolic',\n",
       " '4.2.1 Cognitive simulation',\n",
       " '4.2.2 Logic-based',\n",
       " '4.2.3 Anti-logic or scruffy',\n",
       " '4.2.4 Knowledge-based',\n",
       " '4.3 Sub-symbolic',\n",
       " '4.3.1 Embodied intelligence',\n",
       " '4.3.2 Computational intelligence and soft computing',\n",
       " '4.4 Statistical learning',\n",
       " '4.5 Integrating the approaches',\n",
       " '5 Tools',\n",
       " '5.1 Search and optimization',\n",
       " '5.2 Logic',\n",
       " '5.3 Probabilistic methods for uncertain reasoning',\n",
       " '5.4 Classifiers and statistical learning methods',\n",
       " '5.5 Artificial neural networks',\n",
       " '5.5.1 Deep feedforward neural networks',\n",
       " '5.5.2 Deep recurrent neural networks',\n",
       " '5.6 Evaluating progress',\n",
       " '6 Applications',\n",
       " '6.1 Healthcare',\n",
       " '6.2 Automotive',\n",
       " '6.3 Finance and economics',\n",
       " '6.4 Government',\n",
       " '6.5 Video games',\n",
       " '6.6 Military',\n",
       " '6.7 Audit',\n",
       " '6.8 Advertising',\n",
       " '6.9 Art',\n",
       " '7 Philosophy and ethics',\n",
       " '7.1 The limits of artificial general intelligence',\n",
       " '7.2 Potential harm',\n",
       " '7.2.1 Existential risk',\n",
       " '7.2.2 Devaluation of humanity',\n",
       " '7.2.3 Social justice',\n",
       " '7.2.4 Decrease in demand for human labor',\n",
       " '7.2.5 Autonomous weapons',\n",
       " '7.3 Ethical machines',\n",
       " '7.3.1 Artificial moral agents',\n",
       " '7.3.2 Machine ethics',\n",
       " '7.3.3 Malevolent and friendly AI',\n",
       " '7.4 Machine consciousness, sentience and mind',\n",
       " '7.4.1 Consciousness',\n",
       " '7.4.2 Computationalism and functionalism',\n",
       " '7.4.3 Strong AI hypothesis',\n",
       " '7.4.4 Robot rights',\n",
       " '7.5 Superintelligence',\n",
       " '7.5.1 Technological singularity',\n",
       " '7.5.2 Transhumanism',\n",
       " '8 In fiction',\n",
       " '9 See also',\n",
       " '10 Explanatory notes',\n",
       " '11 References',\n",
       " '11.1 AI textbooks',\n",
       " '11.2 History of AI',\n",
       " '11.3 Other sources',\n",
       " '12 Further reading',\n",
       " '13 External links']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data from the “see also” section, we use the find method to get the div containing the list items, and then use find_all to get an array of list items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "see_also_section = soup.find('div', attrs={'class': 'div-col columns column-width'})\n",
    "see_also_soup =  see_also_section.find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li><a class=\"image\" href=\"/wiki/File:Animation2.gif\"><img alt=\"Animation2.gif\" class=\"noviewer\" data-file-height=\"78\" data-file-width=\"48\" decoding=\"async\" height=\"16\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Animation2.gif/10px-Animation2.gif\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Animation2.gif/15px-Animation2.gif 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Animation2.gif/19px-Animation2.gif 2x\" width=\"10\"/></a> <a href=\"/wiki/Portal:Artificial_intelligence\" title=\"Portal:Artificial intelligence\">Artificial intelligence portal</a></li>,\n",
       " <li><a href=\"/wiki/Abductive_reasoning\" title=\"Abductive reasoning\">Abductive reasoning</a></li>,\n",
       " <li><i><a href=\"/wiki/A.I._Rising\" title=\"A.I. Rising\">A.I. Rising</a></i></li>,\n",
       " <li><a href=\"/wiki/Behavior_selection_algorithm\" title=\"Behavior selection algorithm\">Behavior selection algorithm</a></li>,\n",
       " <li><a href=\"/wiki/Business_process_automation\" title=\"Business process automation\">Business process automation</a></li>,\n",
       " <li><a href=\"/wiki/Case-based_reasoning\" title=\"Case-based reasoning\">Case-based reasoning</a></li>,\n",
       " <li><a href=\"/wiki/Commonsense_reasoning\" title=\"Commonsense reasoning\">Commonsense reasoning</a></li>,\n",
       " <li><a href=\"/wiki/Emergent_algorithm\" title=\"Emergent algorithm\">Emergent algorithm</a></li>,\n",
       " <li><a href=\"/wiki/Evolutionary_computation\" title=\"Evolutionary computation\">Evolutionary computation</a></li>,\n",
       " <li><a href=\"/wiki/Glossary_of_artificial_intelligence\" title=\"Glossary of artificial intelligence\">Glossary of artificial intelligence</a></li>,\n",
       " <li><a href=\"/wiki/Machine_learning\" title=\"Machine learning\">Machine learning</a></li>,\n",
       " <li><a href=\"/wiki/Mathematical_optimization\" title=\"Mathematical optimization\">Mathematical optimization</a></li>,\n",
       " <li><a href=\"/wiki/Multi-agent_system\" title=\"Multi-agent system\">Multi-agent system</a></li>,\n",
       " <li><a href=\"/wiki/Robotic_process_automation\" title=\"Robotic process automation\">Robotic process automation</a></li>,\n",
       " <li><a href=\"/wiki/Soft_computing\" title=\"Soft computing\">Soft computing</a></li>,\n",
       " <li><a href=\"/wiki/Weak_AI\" title=\"Weak AI\">Weak AI</a></li>,\n",
       " <li><a href=\"/wiki/Personality_computing\" title=\"Personality computing\">Personality computing</a></li>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "see_also_soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the hrefs and the text a loop in combination with the find method can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "see_also = []\n",
    "for li in see_also_soup:\n",
    "    a_tag = li.find('a', href=True, attrs={'title':True, 'class':False}) # find a tags that have a title and a class\n",
    "    href = a_tag['href'] # get the href attribute\n",
    "    text = a_tag.getText() # get the text\n",
    "    see_also.append([href, text]) # append to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/wiki/Portal:Artificial_intelligence', 'Artificial intelligence portal'],\n",
       " ['/wiki/Abductive_reasoning', 'Abductive reasoning'],\n",
       " ['/wiki/A.I._Rising', 'A.I. Rising'],\n",
       " ['/wiki/Behavior_selection_algorithm', 'Behavior selection algorithm'],\n",
       " ['/wiki/Business_process_automation', 'Business process automation'],\n",
       " ['/wiki/Case-based_reasoning', 'Case-based reasoning'],\n",
       " ['/wiki/Commonsense_reasoning', 'Commonsense reasoning'],\n",
       " ['/wiki/Emergent_algorithm', 'Emergent algorithm'],\n",
       " ['/wiki/Evolutionary_computation', 'Evolutionary computation'],\n",
       " ['/wiki/Glossary_of_artificial_intelligence',\n",
       "  'Glossary of artificial intelligence'],\n",
       " ['/wiki/Machine_learning', 'Machine learning'],\n",
       " ['/wiki/Mathematical_optimization', 'Mathematical optimization'],\n",
       " ['/wiki/Multi-agent_system', 'Multi-agent system'],\n",
       " ['/wiki/Robotic_process_automation', 'Robotic process automation'],\n",
       " ['/wiki/Soft_computing', 'Soft computing'],\n",
       " ['/wiki/Weak_AI', 'Weak AI'],\n",
       " ['/wiki/Personality_computing', 'Personality computing']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "see_also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data\n",
    "Almost all of the time we would like to save our scraped data, so we can use it later. The easiest way is to save it to a .txt or .csv file by using the open function which is build into Python.\n",
    "\n",
    "We will save the content section into a text file with the name content.txt ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('content.txt', 'w') as f:\n",
    "    for i in content:\n",
    "        f.write(i+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best format for the “see also” data is probably a csv because it has two columns(One for the href and one for the text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('see_also.csv', 'w') as f:\n",
    "    for i in see_also:\n",
    "        f.write(\",\".join(i)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
