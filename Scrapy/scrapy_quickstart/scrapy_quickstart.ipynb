{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scrapy.org/en/latest/intro/overview.html\n",
    "\n",
    "http://quotes.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Scrapy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/45/414e87ac8209d537c91575538c5307c20217a6943f555e0ee39f6db4bb0f/Scrapy-1.6.0-py2.py3-none-any.whl (231kB)\n",
      "\u001b[K    100% |████████████████████████████████| 235kB 2.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /Users/robincole/anaconda3/lib/python3.6/site-packages (from Scrapy) (1.11.0)\n",
      "Requirement already satisfied: Twisted>=13.1.0 in /Users/robincole/.local/lib/python3.6/site-packages (from Scrapy) (18.9.0)\n",
      "Requirement already satisfied: cssselect>=0.9 in /Users/robincole/anaconda3/lib/python3.6/site-packages (from Scrapy) (1.0.3)\n",
      "Collecting queuelib (from Scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/85/ae64e9145f39dd6d14f8af3fa809a270ef3729f3b90b3c0cf5aa242ab0d4/queuelib-1.5.0-py2.py3-none-any.whl\n",
      "Collecting parsel>=1.5 (from Scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/96/69/d1d5dba5e4fecd41ffd71345863ed36a45975812c06ba77798fc15db6a64/parsel-1.5.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: w3lib>=1.17.0 in /Users/robincole/anaconda3/lib/python3.6/site-packages (from Scrapy) (1.19.0)\n",
      "Collecting service-identity (from Scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/7c/2195b890023e098f9618d43ebc337d83c8b38d414326685339eb024db2f6/service_identity-18.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: lxml in /Users/robincole/anaconda3/lib/python3.6/site-packages (from Scrapy) (3.8.0)\n",
      "Requirement already satisfied: pyOpenSSL in /Users/robincole/anaconda3/lib/python3.6/site-packages (from Scrapy) (18.0.0)\n",
      "Collecting PyDispatcher>=2.0.5 (from Scrapy)\n",
      "Requirement already satisfied: zope.interface>=4.4.2 in /Users/robincole/.local/lib/python3.6/site-packages (from Twisted>=13.1.0->Scrapy) (4.6.0)\n",
      "Requirement already satisfied: incremental>=16.10.1 in /Users/robincole/.local/lib/python3.6/site-packages (from Twisted>=13.1.0->Scrapy) (17.5.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /Users/robincole/.local/lib/python3.6/site-packages (from Twisted>=13.1.0->Scrapy) (18.0.0)\n",
      "Requirement already satisfied: Automat>=0.3.0 in /Users/robincole/.local/lib/python3.6/site-packages (from Twisted>=13.1.0->Scrapy) (0.7.0)\n",
      "Requirement already satisfied: constantly>=15.1 in /Users/robincole/.local/lib/python3.6/site-packages (from Twisted>=13.1.0->Scrapy) (15.1.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/robincole/.local/lib/python3.6/site-packages (from Twisted>=13.1.0->Scrapy) (18.2.0)\n",
      "Requirement already satisfied: PyHamcrest>=1.9.0 in /Users/robincole/.local/lib/python3.6/site-packages (from Twisted>=13.1.0->Scrapy) (1.9.0)\n",
      "Requirement already satisfied: cryptography in /Users/robincole/anaconda3/lib/python3.6/site-packages (from service-identity->Scrapy) (2.2.2)\n",
      "Requirement already satisfied: pyasn1 in /Users/robincole/anaconda3/lib/python3.6/site-packages (from service-identity->Scrapy) (0.4.5)\n",
      "Collecting pyasn1-modules (from service-identity->Scrapy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/98/8ddd9fa4d84065926832bcf2255a2b69f1d03330aa4d1c49cc7317ac888e/pyasn1_modules-0.2.4-py2.py3-none-any.whl (66kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 683kB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/robincole/anaconda3/lib/python3.6/site-packages (from zope.interface>=4.4.2->Twisted>=13.1.0->Scrapy) (39.1.0)\n",
      "Requirement already satisfied: idna>=2.5 in /Users/robincole/.local/lib/python3.6/site-packages (from hyperlink>=17.1.1->Twisted>=13.1.0->Scrapy) (2.8)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /Users/robincole/anaconda3/lib/python3.6/site-packages (from cryptography->service-identity->Scrapy) (0.24.0)\n",
      "Requirement already satisfied: cffi>=1.7 in /Users/robincole/anaconda3/lib/python3.6/site-packages (from cryptography->service-identity->Scrapy) (1.11.5)\n",
      "Requirement already satisfied: pycparser in /Users/robincole/anaconda3/lib/python3.6/site-packages (from cffi>=1.7->cryptography->service-identity->Scrapy) (2.18)\n",
      "Installing collected packages: queuelib, parsel, pyasn1-modules, service-identity, PyDispatcher, Scrapy\n",
      "Successfully installed PyDispatcher-2.0.5 Scrapy-1.6.0 parsel-1.5.1 pyasn1-modules-0.2.4 queuelib-1.5.0 service-identity-18.1.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 17:41:20 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: scrapybot)\n",
      "2019-03-17 17:41:20 [scrapy.utils.log] INFO: Versions: lxml 3.8.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.5 |Anaconda, Inc.| (default, Apr 26 2018, 08:42:37) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Darwin-18.2.0-x86_64-i386-64bit\n",
      "2019-03-17 17:41:20 [scrapy.crawler] INFO: Overridden settings: {'FEED_FORMAT': 'json', 'FEED_URI': 'quotes.json', 'SPIDER_LOADER_WARN_ONLY': True}\n",
      "2019-03-17 17:41:20 [scrapy.extensions.telnet] INFO: Telnet Password: d4cb78def63d4caf\n",
      "2019-03-17 17:41:20 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2019-03-17 17:41:20 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2019-03-17 17:41:20 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2019-03-17 17:41:20 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2019-03-17 17:41:20 [scrapy.core.engine] INFO: Spider opened\n",
      "2019-03-17 17:41:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2019-03-17 17:41:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2019-03-17 17:41:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/tag/humor/> (referer: None)\n",
      "2019-03-17 17:41:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
      "{'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'author': 'Jane Austen'}\n",
      "2019-03-17 17:41:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
      "{'text': '“A day without sunshine is like, you know, night.”', 'author': 'Steve Martin'}\n",
      "2019-03-17 17:41:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
      "{'text': '“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”', 'author': 'Garrison Keillor'}\n",
      "2019-03-17 17:41:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
      "{'text': '“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”', 'author': 'Jim Henson'}\n",
      "2019-03-17 17:41:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
      "{'text': \"“All you need is love. But a little chocolate now and then doesn't hurt.”\", 'author': 'Charles M. Schulz'}\n",
      "2019-03-17 17:41:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
      "{'text': \"“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\", 'author': 'Suzanne Collins'}\n",
      "2019-03-17 17:41:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
      "{'text': '“Some people never go crazy. What truly horrible lives they must lead.”', 'author': 'Charles Bukowski'}\n",
      "2019-03-17 17:41:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
      "{'text': '“The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.”', 'author': 'Terry Pratchett'}\n",
      "2019-03-17 17:41:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
      "{'text': '“Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!”', 'author': 'Dr. Seuss'}\n",
      "2019-03-17 17:41:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
      "{'text': '“The reason I talk to myself is because I’m the only one whose answers I accept.”', 'author': 'George Carlin'}\n",
      "2019-03-17 17:41:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/tag/humor/page/2/> (referer: http://quotes.toscrape.com/tag/humor/)\n",
      "2019-03-17 17:41:21 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/page/2/>\n",
      "{'text': '“I am free of all prejudice. I hate everyone equally. ”', 'author': 'W.C. Fields'}\n",
      "2019-03-17 17:41:21 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/page/2/>\n",
      "{'text': \"“A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.”\", 'author': 'Jane Austen'}\n",
      "2019-03-17 17:41:21 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2019-03-17 17:41:21 [scrapy.extensions.feedexport] INFO: Stored json feed (12 items) in: quotes.json\n",
      "2019-03-17 17:41:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 511,\n",
      " 'downloader/request_count': 2,\n",
      " 'downloader/request_method_count/GET': 2,\n",
      " 'downloader/response_bytes': 3725,\n",
      " 'downloader/response_count': 2,\n",
      " 'downloader/response_status_count/200': 2,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2019, 3, 17, 17, 41, 21, 63945),\n",
      " 'item_scraped_count': 12,\n",
      " 'log_count/DEBUG': 14,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 52027392,\n",
      " 'memusage/startup': 52027392,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 2,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'start_time': datetime.datetime(2019, 3, 17, 17, 41, 20, 450116)}\n",
      "2019-03-17 17:41:21 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!scrapy runspider quotes_spider.py -o quotes.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
