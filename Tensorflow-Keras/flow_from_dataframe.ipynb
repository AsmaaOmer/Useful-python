{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A detailed example article demonstrating the flow_from_dataframe function from Keras.\n",
    "\n",
    "* docs -> https://keras.io/preprocessing/image/ & https://www.tensorflow.org/tutorials/load_data/images\n",
    "* article -> https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
    "* dataset -> https://www.kaggle.com/c/cifar-10/data - The CIFAR-10 data consists of 60,000 32x32 color images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images in the official data. We have preserved the train/test split from the original dataset.  \n",
    "\n",
    "Most of the Image datasets that I found online has 2 common formats, \n",
    "\n",
    "1) the first common format contains all the **images within separate folders named after their respective class names**, This is by far the most common format I always see online and Keras allows anyone to utilize the `flow_from_directory` function to easily the images read from the disc and perform powerful on the fly image augmentation with the ImageDataGenerator.\n",
    "\n",
    "2) The second most common format I found online is, all the **images are present inside a single directory and their respective classes are mapped in a CSV or JSON file**. For these we can use `flow_from_dataframe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function flow_from_dataframe in module keras_preprocessing.image.image_data_generator:\n",
      "\n",
      "flow_from_dataframe(self, dataframe, directory=None, x_col='filename', y_col='class', weight_col=None, target_size=(256, 256), color_mode='rgb', classes=None, class_mode='categorical', batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='png', subset=None, interpolation='nearest', validate_filenames=True, **kwargs)\n",
      "    Takes the dataframe and the path to a directory\n",
      "     and generates batches of augmented/normalized data.\n",
      "    \n",
      "    **A simple tutorial can be found **[here](\n",
      "                                http://bit.ly/keras_flow_from_dataframe).\n",
      "    \n",
      "    # Arguments\n",
      "        dataframe: Pandas dataframe containing the filepaths relative to\n",
      "            `directory` (or absolute paths if `directory` is None) of the\n",
      "            images in a string column. It should include other column/s\n",
      "            depending on the `class_mode`:\n",
      "            - if `class_mode` is `\"categorical\"` (default value) it must\n",
      "                include the `y_col` column with the class/es of each image.\n",
      "                Values in column can be string/list/tuple if a single class\n",
      "                or list/tuple if multiple classes.\n",
      "            - if `class_mode` is `\"binary\"` or `\"sparse\"` it must include\n",
      "                the given `y_col` column with class values as strings.\n",
      "            - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should contain\n",
      "            the columns specified in `y_col`.\n",
      "            - if `class_mode` is `\"input\"` or `None` no extra column is needed.\n",
      "        directory: string, path to the directory to read images from. If `None`,\n",
      "            data in `x_col` column should be absolute paths.\n",
      "        x_col: string, column in `dataframe` that contains the filenames (or\n",
      "            absolute paths if `directory` is `None`).\n",
      "        y_col: string or list, column/s in `dataframe` that has the target data.\n",
      "        weight_col: string, column in `dataframe` that contains the sample\n",
      "            weights. Default: `None`.\n",
      "        target_size: tuple of integers `(height, width)`, default: `(256, 256)`.\n",
      "            The dimensions to which all images found will be resized.\n",
      "        color_mode: one of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n",
      "            Whether the images will be converted to have 1 or 3 color channels.\n",
      "        classes: optional list of classes (e.g. `['dogs', 'cats']`).\n",
      "            Default: None. If not provided, the list of classes will be\n",
      "            automatically inferred from the `y_col`,\n",
      "            which will map to the label indices, will be alphanumeric).\n",
      "            The dictionary containing the mapping from class names to class\n",
      "            indices can be obtained via the attribute `class_indices`.\n",
      "        class_mode: one of \"binary\", \"categorical\", \"input\", \"multi_output\",\n",
      "            \"raw\", sparse\" or None. Default: \"categorical\".\n",
      "            Mode for yielding the targets:\n",
      "            - `\"binary\"`: 1D numpy array of binary labels,\n",
      "            - `\"categorical\"`: 2D numpy array of one-hot encoded labels.\n",
      "                Supports multi-label output.\n",
      "            - `\"input\"`: images identical to input images (mainly used to\n",
      "                work with autoencoders),\n",
      "            - `\"multi_output\"`: list with the values of the different columns,\n",
      "            - `\"raw\"`: numpy array of values in `y_col` column(s),\n",
      "            - `\"sparse\"`: 1D numpy array of integer labels,\n",
      "            - `None`, no targets are returned (the generator will only yield\n",
      "                batches of image data, which is useful to use in\n",
      "                `model.predict_generator()`).\n",
      "        batch_size: size of the batches of data (default: 32).\n",
      "        shuffle: whether to shuffle the data (default: True)\n",
      "        seed: optional random seed for shuffling and transformations.\n",
      "        save_to_dir: None or str (default: None).\n",
      "            This allows you to optionally specify a directory\n",
      "            to which to save the augmented pictures being generated\n",
      "            (useful for visualizing what you are doing).\n",
      "        save_prefix: str. Prefix to use for filenames of saved pictures\n",
      "            (only relevant if `save_to_dir` is set).\n",
      "        save_format: one of \"png\", \"jpeg\"\n",
      "            (only relevant if `save_to_dir` is set). Default: \"png\".\n",
      "        follow_links: whether to follow symlinks inside class subdirectories\n",
      "            (default: False).\n",
      "        subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
      "            `validation_split` is set in `ImageDataGenerator`.\n",
      "        interpolation: Interpolation method used to resample the image if the\n",
      "            target size is different from that of the loaded image.\n",
      "            Supported methods are `\"nearest\"`, `\"bilinear\"`, and `\"bicubic\"`.\n",
      "            If PIL version 1.1.3 or newer is installed, `\"lanczos\"` is also\n",
      "            supported. If PIL version 3.4.0 or newer is installed, `\"box\"` and\n",
      "            `\"hamming\"` are also supported. By default, `\"nearest\"` is used.\n",
      "        validate_filenames: Boolean, whether to validate image filenames in\n",
      "            `x_col`. If `True`, invalid images will be ignored. Disabling this\n",
      "            option can lead to speed-up in the execution of this function.\n",
      "            Default: `True`.\n",
      "    \n",
      "    # Returns\n",
      "        A `DataFrameIterator` yielding tuples of `(x, y)`\n",
      "        where `x` is a numpy array containing a batch\n",
      "        of images with shape `(batch_size, *target_size, channels)`\n",
      "        and `y` is a numpy array of corresponding labels.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.keras.preprocessing.image.ImageDataGenerator.flow_from_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path(\"/Users/robin/Kaggle/cifar-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/robin/Kaggle/cifar-10/sampleSubmission.csv'),\n",
       " PosixPath('/Users/robin/Kaggle/cifar-10/creditcard.csv'),\n",
       " PosixPath('/Users/robin/Kaggle/cifar-10/trainLabels.csv')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[file for file in directory.glob('*.csv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/robin/Kaggle/cifar-10/train')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = directory / 'train'\n",
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/robin/Kaggle/cifar-10/train/20037.png'),\n",
       " PosixPath('/Users/robin/Kaggle/cifar-10/train/3975.png'),\n",
       " PosixPath('/Users/robin/Kaggle/cifar-10/train/49081.png'),\n",
       " PosixPath('/Users/robin/Kaggle/cifar-10/train/38678.png'),\n",
       " PosixPath('/Users/robin/Kaggle/cifar-10/train/30224.png')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = [file for file in train_dir.glob(\"*\")]\n",
    "print(len(train_files))\n",
    "train_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/robin/Kaggle/cifar-10/test')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir = directory / 'test'\n",
    "test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/robin/Kaggle/cifar-10/test/20037.png'),\n",
       " PosixPath('/Users/robin/Kaggle/cifar-10/test/124219.png'),\n",
       " PosixPath('/Users/robin/Kaggle/cifar-10/test/270196.png'),\n",
       " PosixPath('/Users/robin/Kaggle/cifar-10/test/3975.png'),\n",
       " PosixPath('/Users/robin/Kaggle/cifar-10/test/66062.png')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files = [file for file in test_dir.glob(\"*\")]\n",
    "print(len(test_files))\n",
    "test_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframes\n",
    "`trainLabels.csv` maps the file `id` to the class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(str(directory / \"trainLabels.csv\"), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49996</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49997</td>\n",
       "      <td>frog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49998</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49999</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>50000</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id       label\n",
       "49995  49996        bird\n",
       "49996  49997        frog\n",
       "49997  49998       truck\n",
       "49998  49999  automobile\n",
       "49999  50000  automobile"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['frog',\n",
       " 'truck',\n",
       " 'deer',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'airplane']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(train_df['label'].unique())\n",
    "print(len(labels))\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `id` we generate the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['filename'] = train_df['id'].apply(lambda x : x + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>frog</td>\n",
       "      <td>1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>truck</td>\n",
       "      <td>2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>truck</td>\n",
       "      <td>3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>deer</td>\n",
       "      <td>4.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>automobile</td>\n",
       "      <td>5.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id       label filename\n",
       "0  1        frog    1.png\n",
       "1  2       truck    2.png\n",
       "2  3       truck    3.png\n",
       "3  4        deer    4.png\n",
       "4  5  automobile    5.png"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create the test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv(str(directory / \"sampleSubmission.csv\"),dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['filename'] = test_df['id'].apply(lambda x : x + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageDataGenerator\n",
    "Notice below that I split the train set to 2 sets one for training and the other for validation just by specifying the argument validation_split=0.25 which splits the dataset into to 2 sets where the validation set will have 25% of the total images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255., validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37500 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=str(directory / 'train'),\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"label\",\n",
    "    subset=\"training\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(32,32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=str(directory / 'train'),\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"label\",\n",
    "    subset=\"validation\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(32,32)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=str(directory / 'test'),\n",
    "    x_col=\"filename\",\n",
    "    y_col=None,\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(32,32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
