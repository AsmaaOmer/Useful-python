{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of pruning_with_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JCkPHee-alKM"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JCkPHee-alKM"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "cvrknnPsaqaM",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Zt0JEl38SWX"
      },
      "source": [
        "# Magnitude-based weight pruning with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IwBSTsryazfT"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/model-optimization/blob/master/tensorflow_model_optimization/g3doc/guide/pruning/pruning_with_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/model-optimization/blob/master/tensorflow_model_optimization/g3doc/guide/pruning/pruning_with_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L7IGLmaw5DjA"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Welcome to the tutorial for *weight pruning*, part of the TensorFlow Model Optimization toolkit.\n",
        "\n",
        "#### What is weight pruning?\n",
        "\n",
        "Weight pruning means literally that: eliminating unnecessary values in the weight tensor. We are practically setting neural network parameters' values to zero to remove low-weight connections between the *layers* of a neural network.\n",
        "\n",
        "#### Why is useful?\n",
        "\n",
        "Tensors with several values set to zero can be considered *sparse*. This results in important benefits:\n",
        "* *Compression*. Sparse tensors are amenable to compression by only keeping the non-zero values and their corresponding coordinates.\n",
        "* *Speed*. Sparse tensors allow us to skip otherwise unnecessary computations involving the zero values.\n",
        "\n",
        "#### How does it work?\n",
        "\n",
        "Our Keras-based weight pruning API is designed to iteratively remove connections based on their magnitude, during training. For more details on the usage of the API, please refer to the GitHub page.\n",
        "\n",
        "In this tutorial, we'll walk you through an end-to-end example of using the weight pruning API on a simple MNIST model. We will show that by simply using a generic file compression algorithm (e.g. zip) the Keras model will be reduced in size, and that this size reduction persists when converted to a Tensorflow Lite format.\n",
        "\n",
        "Two things worth clarifying:\n",
        "* The technique and API are not TensorFlow Lite specific --we just show its application on the TensorFlow Lite backend, as it covers size-sensitive use-cases.\n",
        "* By itself, a sparse model will not be faster to execute. It just enables backends with such capability. In the near future, however, TensorFlow Lite will take advantage of the sparsity to speed up computations.\n",
        "\n",
        "To recap, in the tutorial we will:\n",
        "1.   Train a MNIST model with Keras from scratch.\n",
        "2.   Train a pruned MNIST with the pruning API.\n",
        "3.   Compare the size of the pruned model and the non-pruned one after compression.\n",
        "4.   Convert the pruned model to Tensorflow Lite format and verify that accuracy persists.\n",
        "5.   Show how the pruned model works with other optimization techniques, like post-training quantization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P8qFbkru8FKu"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q8zIQsT9mUTw"
      },
      "source": [
        "To use the pruning API, install the `tensorflow-model-optimization` package. See the [TensorFlow model optimization repo](https://github.com/tensorflow/model-optimization) for compatible API versions.\n",
        "\n",
        "Since you will train a few models in this tutorial, install the `tensorflow-gpu` package to speed up things. Enable the GPU with: *Runtime > Change runtime type > Hardware accelator* and make sure GPU is selected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pn836LSTNSHA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "2384c29a-389b-44c9-c418-5ebb7eb58406"
      },
      "source": [
        "! pip uninstall -y tensorflow\n",
        "! pip uninstall -y tf-nightly\n",
        "! pip install -U tensorflow-gpu==1.14.0\n",
        "\n",
        "! pip install tensorflow-model-optimization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.15.0:\n",
            "  Successfully uninstalled tensorflow-1.15.0\n",
            "\u001b[33mWARNING: Skipping tf-nightly as it is not installed.\u001b[0m\n",
            "Collecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 42kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 40.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.17.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 52.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (41.4.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.8.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n",
            "Collecting tensorflow-model-optimization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/f9/6eba3e5c5bbee217d33a9babeb609bf5077381401da44fb966b4d3e3cb4d/tensorflow_model_optimization-0.1.3-py2.py3-none-any.whl (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.12.0)\n",
            "Collecting enum34~=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/af/42/cb9355df32c69b553e72a2e28daee25d1611d2c0d9c272aa1d34204205b2/enum34-1.1.6-py3-none-any.whl\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.17.3)\n",
            "Installing collected packages: enum34, tensorflow-model-optimization\n",
            "Successfully installed enum34-1.1.6 tensorflow-model-optimization-0.1.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ykjgo4UNXmD",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "import tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mydXeQlDNbnR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "e78ea788-4db6-4ee8-f158-dabb88a4cb9c"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import tempfile\n",
        "import zipfile\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gBYltugp-MdR"
      },
      "source": [
        "## Prepare the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P_MJqxz5z2dh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "20f5e7cb-c429-4844-a2c2-70d363745db7"
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "if tf.keras.backend.image_data_format() == 'channels_first':\n",
        "  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "  input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "  input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OmdnYKPK--5L"
      },
      "source": [
        "## Train a MNIST model without pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r1p_y3gPWeW2"
      },
      "source": [
        "### Build the MNIST model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uLg0SGdYp2Q6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "df314361-a3ad-444b-a3b5-8e0e3217acc7"
      },
      "source": [
        "l = tf.keras.layers\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    l.Conv2D(\n",
        "        32, 5, padding='same', activation='relu', input_shape=input_shape),\n",
        "    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "    l.BatchNormalization(),\n",
        "    l.Conv2D(64, 5, padding='same', activation='relu'),\n",
        "    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "    l.Flatten(),\n",
        "    l.Dense(1024, activation='relu'),\n",
        "    l.Dropout(0.4),\n",
        "    l.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 14, 14, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              3212288   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 3,274,762\n",
            "Trainable params: 3,274,698\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5dHynoso_xXF"
      },
      "source": [
        "### Train the model to reach an accuracy >99%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KGo0UICmA8J3"
      },
      "source": [
        "\n",
        "Load [TensorBoard](https://www.tensorflow.org/tensorboard) to monitor the training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WJyS_IcQBBqg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6a09e9b-b7fd-4804-fc25-c92ab83a350c"
      },
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "print('Writing training logs to ' + logdir)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing training logs to /tmp/tmpws0emfzs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QfgjuOLj_mFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c916e3ab-97fc-4111-dfd8-8a1583782127"
      },
      "source": [
        "%tensorboard --logdir={logdir}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A7c-fsQpTzOr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "6c2ee006-e138-4b97-d3ac-d9603a681c72"
      },
      "source": [
        "callbacks = [tf.keras.callbacks.TensorBoard(log_dir=logdir, profile_batch=0)]\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          callbacks=callbacks,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 11s 189us/sample - loss: 0.3549 - acc: 0.9389 - val_loss: 0.1173 - val_acc: 0.9800\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.0457 - acc: 0.9860 - val_loss: 0.0292 - val_acc: 0.9901\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.0315 - acc: 0.9899 - val_loss: 0.0328 - val_acc: 0.9897\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.0246 - acc: 0.9921 - val_loss: 0.0288 - val_acc: 0.9905\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0203 - acc: 0.9933 - val_loss: 0.0344 - val_acc: 0.9893\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.0165 - acc: 0.9945 - val_loss: 0.0306 - val_acc: 0.9904\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0161 - acc: 0.9950 - val_loss: 0.0265 - val_acc: 0.9915\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0142 - acc: 0.9955 - val_loss: 0.0326 - val_acc: 0.9910\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0134 - acc: 0.9956 - val_loss: 0.0278 - val_acc: 0.9934\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0118 - acc: 0.9963 - val_loss: 0.0402 - val_acc: 0.9912\n",
            "Test loss: 0.0402483103722368\n",
            "Test accuracy: 0.9912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eLgMavDVCde5"
      },
      "source": [
        "### Save the original model for size comparison later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8E6U7GUIx5r9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff946f19-adc3-42b0-fa71-ba76ab595056"
      },
      "source": [
        "# Backend agnostic way to save/restore models\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving model to: ', keras_file)\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to:  /tmp/tmp3_4su7_j.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gWiQbobKC0NZ"
      },
      "source": [
        "## Train a pruned MNIST\n",
        "\n",
        "We provide a `prune_low_magnitude()` API to train models with removed connections. The Keras-based API can be applied at the level of individual layers, or the entire model. We will show you the usage of both in the following sections.\n",
        "\n",
        "At a high level, the technique works by iteratively removing (i.e. zeroing out) connections between layers, given an schedule and a target sparsity.\n",
        "\n",
        "For example, a typical configuration will target a 75% sparsity, by pruning connections every 100 steps (aka epochs), starting from step 2,000. For more details on the possible configurations, please refer to the github documentation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FfJ6Tm3KXMFY"
      },
      "source": [
        "### Build a pruned model layer by layer\n",
        "In this example, we show how to use the API at the level of layers, and build a pruned MNIST solver model.\n",
        "\n",
        "In this case, the `prune_low_magnitude(`) \n",
        "receives as parameter the Keras layer whose weights we want pruned.\n",
        "\n",
        "This function requires a pruning params which configures the pruning algorithm during training. Please refer to our github page for detailed documentation. The parameter used here means:\n",
        "\n",
        "\n",
        "1.   **Sparsity.** PolynomialDecay is used across the whole training process. We start at the sparsity level 50% and gradually train the model to reach 90% sparsity. X% sparsity means that X% of the weight tensor is going to be pruned away.\n",
        "2.   **Schedule**. Connections are pruned starting from step 2000 to the end of training, and runs every 100 steps. The reasoning behind this is that we want to train the model without pruning for a few epochs to reach a certain accuracy, to aid convergence. Furthermore, we give the model some time to recover after each pruning step, so pruning does not happen on every step. We set the pruning frequency to 100.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ip8qCtSlU3TQ",
        "colab": {}
      },
      "source": [
        "from tensorflow_model_optimization.sparsity import keras as sparsity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tA9rnRUrebTE"
      },
      "source": [
        "To demonstrate how to save and restore a pruned keras model, in the following example we first train the model for 10 epochs, save it to disk, and finally restore and continue training for 2 epochs. With gradual sparsity, four important parameters are begin_sparsity, final_sparsity, begin_step and end_step. The first three are straight forward. Let's calculate the end step given the number of train example, batch size, and the total epochs to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rrs-xoB2cSSQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e601d10d-7bf1-4917-9072-01ad6f591a68"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "epochs = 12\n",
        "num_train_samples = x_train.shape[0]\n",
        "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
        "print('End step: ' + str(end_step))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "End step: 5628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Shz-r2RiqFca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "1267e9c1-3608-4132-a15d-7a3f3ca7fecd"
      },
      "source": [
        "pruning_params = {\n",
        "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                   final_sparsity=0.90,\n",
        "                                                   begin_step=2000,\n",
        "                                                   end_step=end_step,\n",
        "                                                   frequency=100)\n",
        "}\n",
        "\n",
        "pruned_model = tf.keras.Sequential([\n",
        "    sparsity.prune_low_magnitude(\n",
        "        l.Conv2D(32, 5, padding='same', activation='relu'),\n",
        "        input_shape=input_shape,\n",
        "        **pruning_params),\n",
        "    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "    l.BatchNormalization(),\n",
        "    sparsity.prune_low_magnitude(\n",
        "        l.Conv2D(64, 5, padding='same', activation='relu'), **pruning_params),\n",
        "    l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "    l.Flatten(),\n",
        "    sparsity.prune_low_magnitude(l.Dense(1024, activation='relu'),\n",
        "                                 **pruning_params),\n",
        "    l.Dropout(0.4),\n",
        "    sparsity.prune_low_magnitude(l.Dense(num_classes, activation='softmax'),\n",
        "                                 **pruning_params)\n",
        "])\n",
        "\n",
        "pruned_model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_schedule.py:240: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_conv2d_2 (None, 28, 28, 32)        1634      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 32)        128       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv2d_3 (None, 14, 14, 64)        102466    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_2  (None, 1024)              6423554   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_3  (None, 10)                20492     \n",
            "=================================================================\n",
            "Total params: 6,548,274\n",
            "Trainable params: 3,274,698\n",
            "Non-trainable params: 3,273,576\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YczppQ6vEPJg"
      },
      "source": [
        "Load Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eIO8UpZyEYkp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c41d1bb5-219a-44a9-aa24-444a8a0e51b5"
      },
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "print('Writing training logs to ' + logdir)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing training logs to /tmp/tmpg2yrkgcj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KKb8XpDkA8TN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "388211d3-497f-49e4-c9fc-2f00fc293435"
      },
      "source": [
        "%tensorboard --logdir={logdir}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6007\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z2166laKE_N6"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "Start pruning from step 2000 when accuracy >98%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GGoOTwQRzEP4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7d775fb-9868-44ed-fda3-1d092614dea5"
      },
      "source": [
        "pruned_model.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "# Add a pruning step callback to peg the pruning step to the optimizer's\n",
        "# step. Also add a callback to add pruning summaries to tensorboard\n",
        "callbacks = [\n",
        "    sparsity.UpdatePruningStep(),\n",
        "    sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
        "]\n",
        "\n",
        "pruned_model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          callbacks=callbacks,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "score = pruned_model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1947 - acc: 0.9452INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 12s 206us/sample - loss: 0.1944 - acc: 0.9452 - val_loss: 0.1125 - val_acc: 0.9779\n",
            "Epoch 2/10\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9844INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 11s 182us/sample - loss: 0.0503 - acc: 0.9844 - val_loss: 0.0292 - val_acc: 0.9904\n",
            "Epoch 3/10\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9893INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 10s 164us/sample - loss: 0.0338 - acc: 0.9893 - val_loss: 0.0248 - val_acc: 0.9909\n",
            "Epoch 4/10\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9912INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 10s 160us/sample - loss: 0.0276 - acc: 0.9912 - val_loss: 0.0262 - val_acc: 0.9920\n",
            "Epoch 5/10\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9933INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 10s 169us/sample - loss: 0.0214 - acc: 0.9934 - val_loss: 0.0257 - val_acc: 0.9914\n",
            "Epoch 6/10\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9944INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.0173 - acc: 0.9944 - val_loss: 0.0230 - val_acc: 0.9919\n",
            "Epoch 7/10\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9958INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 11s 176us/sample - loss: 0.0136 - acc: 0.9959 - val_loss: 0.0221 - val_acc: 0.9918\n",
            "Epoch 8/10\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9953INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 11s 177us/sample - loss: 0.0152 - acc: 0.9952 - val_loss: 0.0241 - val_acc: 0.9932\n",
            "Epoch 9/10\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9956INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 11s 185us/sample - loss: 0.0144 - acc: 0.9956 - val_loss: 0.0231 - val_acc: 0.9932\n",
            "Epoch 10/10\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9961INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 11s 182us/sample - loss: 0.0131 - acc: 0.9961 - val_loss: 0.0210 - val_acc: 0.9932\n",
            "Test loss: 0.021024110769868275\n",
            "Test accuracy: 0.9932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Nzrm5pN1viP"
      },
      "source": [
        "### Save and restore the pruned model\n",
        "\n",
        "Continue training for two epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rd8G7srV2dcI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "70168cf8-5c6c-4d89-ab97-3ec7e6afe441"
      },
      "source": [
        "_, checkpoint_file = tempfile.mkstemp('.h5')\n",
        "print('Saving pruned model to: ', checkpoint_file)\n",
        "# saved_model() sets include_optimizer to True by default. Spelling it out here\n",
        "# to highlight.\n",
        "tf.keras.models.save_model(pruned_model, checkpoint_file, include_optimizer=True)\n",
        "\n",
        "with sparsity.prune_scope():\n",
        "  restored_model = tf.keras.models.load_model(checkpoint_file)\n",
        "\n",
        "restored_model.fit(x_train, y_train,\n",
        "                   batch_size=batch_size,\n",
        "                   epochs=2,\n",
        "                   verbose=1,\n",
        "                   callbacks=callbacks,\n",
        "                   validation_data=(x_test, y_test))\n",
        "\n",
        "score = restored_model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving pruned model to:  /tmp/tmp078f4gn_.h5\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9967INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2_1/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3_1/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2_1/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3_1/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 13s 218us/sample - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0205 - val_acc: 0.9933\n",
            "Epoch 2/2\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9977INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_2_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_3_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_2_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_3_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_2_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_2_1/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_3_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_3_1/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_2_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_2_1/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_3_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_3_1/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 11s 191us/sample - loss: 0.0078 - acc: 0.9977 - val_loss: 0.0221 - val_acc: 0.9926\n",
            "Test loss: 0.022081617123876005\n",
            "Test accuracy: 0.9926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1vV7pZrW5TQh"
      },
      "source": [
        "In the example above, a few things to note are:\n",
        "\n",
        "\n",
        "*   When saving the model, include_optimizer must be set to True. We need to preserve the state of the optimizer across training sessions for pruning to work properly.\n",
        "*   When loading the pruned model, you need the prune_scope() for deseriazliation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tMTFhyc0vAA3"
      },
      "source": [
        "### Strip the pruning wrappers from the pruned model before export for serving\n",
        "Before exporting a serving model, you'd need to call the `strip_pruning` API to strip the pruning wrappers from the model, as it's only needed for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jyCjjpUjvImz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "51c8baa5-5249-4e5b-9c39-a4617a47b80a"
      },
      "source": [
        "final_model = sparsity.strip_pruning(pruned_model)\n",
        "final_model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              3212288   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 3,274,762\n",
            "Trainable params: 3,274,698\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B63tViKp_qLK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c46ef83-11d6-4af0-e0ad-e994dc1a4a38"
      },
      "source": [
        "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving pruned model to: ', pruned_keras_file)\n",
        "\n",
        "# No need to save the optimizer with the graph for serving.\n",
        "tf.keras.models.save_model(final_model, pruned_keras_file, include_optimizer=False)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving pruned model to:  /tmp/tmpg3zxn29v.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GhXHuBAGOBvY"
      },
      "source": [
        "### Compare the size of the unpruned vs. pruned model after compression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hk4DoZTIy2uU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "87e34d13-e41e-4429-f6bc-90430097df1a"
      },
      "source": [
        "_, zip1 = tempfile.mkstemp('.zip') \n",
        "with zipfile.ZipFile(zip1, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "  f.write(keras_file)\n",
        "print(\"Size of the unpruned model before compression: %.2f Mb\" % \n",
        "      (os.path.getsize(keras_file) / float(2**20)))\n",
        "print(\"Size of the unpruned model after compression: %.2f Mb\" % \n",
        "      (os.path.getsize(zip1) / float(2**20)))\n",
        "\n",
        "_, zip2 = tempfile.mkstemp('.zip') \n",
        "with zipfile.ZipFile(zip2, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "  f.write(pruned_keras_file)\n",
        "print(\"Size of the pruned model before compression: %.2f Mb\" % \n",
        "      (os.path.getsize(pruned_keras_file) / float(2**20)))\n",
        "print(\"Size of the pruned model after compression: %.2f Mb\" % \n",
        "      (os.path.getsize(zip2) / float(2**20)))\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the unpruned model before compression: 12.52 Mb\n",
            "Size of the unpruned model after compression: 11.59 Mb\n",
            "Size of the pruned model before compression: 12.52 Mb\n",
            "Size of the pruned model after compression: 2.50 Mb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dayb_w_GqWs_"
      },
      "source": [
        "### Prune a whole model\n",
        "\n",
        "The `prune_low_magnitude` function can also be applied to the entire Keras model. \n",
        "\n",
        "In this case, the algorithm will be applied to all layers that are ameanable to weight pruning (that the API knows about). Layers that the API knows are not ameanable to weight pruning will be ignored, and unknown layers to the API will cause an error.\n",
        "\n",
        "*If your model has layers that the API does not know how to prune their weights, but are perfectly fine to leave \"un-pruned\", then just apply the API in a per-layer basis.*\n",
        "\n",
        "Regarding pruning configuration, the same settings apply to all prunable layers in the model.\n",
        "\n",
        "Also noteworthy is that pruning doesn't preserve the optimizer associated with the original model. As a result, it is necessary to re-compile the pruned model with a new optimizer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I-W7Sj8fZjeb"
      },
      "source": [
        "Before we move forward with the example, lets address the common use case where you may already have a serialized pre-trained Keras model, which you would like to apply weight pruning on. We will take the original MNIST model trained previously to show how this works. In this case, you start by loading the model into memory like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qJm1SJxfqy2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4aad11d4-deac-473f-e30e-d95e3f59cef3"
      },
      "source": [
        "# Load the serialized model\n",
        "loaded_model = tf.keras.models.load_model(keras_file)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "etYrWnrSMpB5"
      },
      "source": [
        "Then you can prune the model loaded and compile the pruned model for training. In this case training will restart from step 0. Given the model we loadded already reached a satisfactory accuracy, we can start pruning immediately. As a result, we set the begin_step to 0 here, and only train for another four epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CabnOldzrSN2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "629f87b1-6537-4136-fd09-8d62e6b6348d"
      },
      "source": [
        "epochs = 4\n",
        "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
        "print(end_step)\n",
        "\n",
        "new_pruning_params = {\n",
        "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                   final_sparsity=0.90,\n",
        "                                                   begin_step=0,\n",
        "                                                   end_step=end_step,\n",
        "                                                   frequency=100)\n",
        "}\n",
        "\n",
        "new_pruned_model = sparsity.prune_low_magnitude(model, **new_pruning_params)\n",
        "new_pruned_model.summary()\n",
        "\n",
        "new_pruned_model.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1876\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_conv2d ( (None, 28, 28, 32)        1634      \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 14, 14, 32)        1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_batch_no (None, 14, 14, 32)        129       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv2d_1 (None, 14, 14, 64)        102466    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 7, 7, 64)          1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 3136)              1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 1024)              6423554   \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dropout  (None, 1024)              1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_1  (None, 10)                20492     \n",
            "=================================================================\n",
            "Total params: 6,548,279\n",
            "Trainable params: 3,274,698\n",
            "Non-trainable params: 3,273,581\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9qCipfCnaY7g"
      },
      "source": [
        "Load tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VPBlcTXWB9tx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64fab48f-34b8-4c4a-e577-fc60ace59626"
      },
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "print('Writing training logs to ' + logdir)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing training logs to /tmp/tmpj7iq225_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X43ix4NZCDNS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "67ee6f83-b595-4461-eaed-d2fc09e7a68f"
      },
      "source": [
        "%tensorboard --logdir={logdir}"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6008\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r2hLPO7KNKq_"
      },
      "source": [
        "### Train the model for another four epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "36hymxokrnbw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "15abc732-8aed-4f26-ccbe-67b99ccd5cde"
      },
      "source": [
        "# Add a pruning step callback to peg the pruning step to the optimizer's\n",
        "# step. Also add a callback to add pruning summaries to tensorboard\n",
        "callbacks = [\n",
        "    sparsity.UpdatePruningStep(),\n",
        "    sparsity.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
        "]\n",
        "\n",
        "new_pruned_model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          callbacks=callbacks,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "score = new_pruned_model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/4\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9954INFO:tensorflow:Summary name prune_low_magnitude_conv2d/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense/mask:0/sparsity is illegal; using prune_low_magnitude_dense/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense/threshold:0/threshold is illegal; using prune_low_magnitude_dense/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_1/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 15s 248us/sample - loss: 0.0141 - acc: 0.9954 - val_loss: 0.0308 - val_acc: 0.9899\n",
            "Epoch 2/4\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9940INFO:tensorflow:Summary name prune_low_magnitude_conv2d/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense/mask:0/sparsity is illegal; using prune_low_magnitude_dense/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense/threshold:0/threshold is illegal; using prune_low_magnitude_dense/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_1/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 13s 210us/sample - loss: 0.0187 - acc: 0.9940 - val_loss: 0.0392 - val_acc: 0.9876\n",
            "Epoch 3/4\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9919INFO:tensorflow:Summary name prune_low_magnitude_conv2d/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense/mask:0/sparsity is illegal; using prune_low_magnitude_dense/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense/threshold:0/threshold is illegal; using prune_low_magnitude_dense/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_1/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 13s 209us/sample - loss: 0.0250 - acc: 0.9919 - val_loss: 0.0295 - val_acc: 0.9914\n",
            "Epoch 4/4\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9943INFO:tensorflow:Summary name prune_low_magnitude_conv2d/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/mask:0/sparsity is illegal; using prune_low_magnitude_conv2d_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense/mask:0/sparsity is illegal; using prune_low_magnitude_dense/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/mask:0/sparsity is illegal; using prune_low_magnitude_dense_1/mask_0/sparsity instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_conv2d_1/threshold:0/threshold is illegal; using prune_low_magnitude_conv2d_1/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense/threshold:0/threshold is illegal; using prune_low_magnitude_dense/threshold_0/threshold instead.\n",
            "INFO:tensorflow:Summary name prune_low_magnitude_dense_1/threshold:0/threshold is illegal; using prune_low_magnitude_dense_1/threshold_0/threshold instead.\n",
            "60000/60000 [==============================] - 12s 205us/sample - loss: 0.0172 - acc: 0.9943 - val_loss: 0.0241 - val_acc: 0.9924\n",
            "Test loss: 0.024123433028522958\n",
            "Test accuracy: 0.9924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z0yphbuRarfT"
      },
      "source": [
        "### Export the pruned model for serving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "anFHUpCXrxMe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "26ebcc7c-76d8-4f24-b877-450330767e3a"
      },
      "source": [
        "final_model = sparsity.strip_pruning(pruned_model)\n",
        "final_model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              3212288   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 3,274,762\n",
            "Trainable params: 3,274,698\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4CmEtxHEso7g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b67db521-47bb-406b-9ad0-00bfba1468f1"
      },
      "source": [
        "_, new_pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "print('Saving pruned model to: ', new_pruned_keras_file)\n",
        "tf.keras.models.save_model(final_model, new_pruned_keras_file, \n",
        "                        include_optimizer=False)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving pruned model to:  /tmp/tmpzofux26x.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YT8YqXAza3Tt"
      },
      "source": [
        "The model size after compression is the same as the one pruned layer-by-layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AtKANC0hs2RR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0f68a0a9-905e-41f3-b062-7ae4d8ee14b3"
      },
      "source": [
        "_, zip3 = tempfile.mkstemp('.zip')\n",
        "with zipfile.ZipFile(zip3, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "  f.write(new_pruned_keras_file)\n",
        "print(\"Size of the pruned model before compression: %.2f Mb\" \n",
        "      % (os.path.getsize(new_pruned_keras_file) / float(2**20)))\n",
        "print(\"Size of the pruned model after compression: %.2f Mb\" \n",
        "      % (os.path.getsize(zip3) / float(2**20)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the pruned model before compression: 12.52 Mb\n",
            "Size of the pruned model after compression: 2.50 Mb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zXrLGUPfIwvV"
      },
      "source": [
        "## Convert to TensorFlow Lite\n",
        "\n",
        "Finally, you can convert the pruned model to a format that's runnable on your targeting backend. Tensorflow Lite is an example format you can use to deploy to mobile devices. To convert to a Tensorflow Lite graph, you need to use the TFLiteConverter as below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1f9Eb2K0bcJG"
      },
      "source": [
        "### Convert the model with TFLiteConverter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ctqfiix-H-x7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3945a524-f708-408f-e81c-ef7fe5d76f47"
      },
      "source": [
        "tflite_model_file = '/tmp/sparse_mnist.tflite'\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model_file(pruned_keras_file)\n",
        "tflite_model = converter.convert()\n",
        "with open(tflite_model_file, 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "INFO:tensorflow:Converted 12 variables to const ops.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fdIiNnrPANcw"
      },
      "source": [
        "### Size of the TensorFlow Lite model after compression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iYMSXAU1AUYI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e153d2db-4bfd-4af7-eb34-6f11dadcf658"
      },
      "source": [
        "_, zip_tflite = tempfile.mkstemp('.zip')\n",
        "with zipfile.ZipFile(zip_tflite, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "  f.write(tflite_model_file)\n",
        "print(\"Size of the tflite model before compression: %.2f Mb\" \n",
        "      % (os.path.getsize(tflite_model_file) / float(2**20)))\n",
        "print(\"Size of the tflite model after compression: %.2f Mb\" \n",
        "      % (os.path.getsize(zip_tflite) / float(2**20)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the tflite model before compression: 12.49 Mb\n",
            "Size of the tflite model after compression: 2.43 Mb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vBqUX1qopV1k"
      },
      "source": [
        "### Evaluate the accuracy of the TensorFlow Lite model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F5AY-TuivmbP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b642eb86-f699-4bc3-e1a0-1307283bbbf6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
        "interpreter.allocate_tensors()\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "def eval_model(interpreter, x_test, y_test):\n",
        "  total_seen = 0\n",
        "  num_correct = 0\n",
        "\n",
        "  for img, label in zip(x_test, y_test):\n",
        "    inp = img.reshape((1, 28, 28, 1))\n",
        "    total_seen += 1\n",
        "    interpreter.set_tensor(input_index, inp)\n",
        "    interpreter.invoke()\n",
        "    predictions = interpreter.get_tensor(output_index)\n",
        "    if np.argmax(predictions) == np.argmax(label):\n",
        "      num_correct += 1\n",
        "\n",
        "    if total_seen % 1000 == 0:\n",
        "        print(\"Accuracy after %i images: %f\" %\n",
        "              (total_seen, float(num_correct) / float(total_seen)))\n",
        "\n",
        "  return float(num_correct) / float(total_seen)\n",
        "\n",
        "print(eval_model(interpreter, x_test, y_test))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy after 1000 images: 0.993000\n",
            "Accuracy after 2000 images: 0.990000\n",
            "Accuracy after 3000 images: 0.989000\n",
            "Accuracy after 4000 images: 0.990000\n",
            "Accuracy after 5000 images: 0.990400\n",
            "Accuracy after 6000 images: 0.991000\n",
            "Accuracy after 7000 images: 0.991714\n",
            "Accuracy after 8000 images: 0.992750\n",
            "Accuracy after 9000 images: 0.993333\n",
            "Accuracy after 10000 images: 0.993200\n",
            "0.9932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zalu5Ng7D7xi"
      },
      "source": [
        "### Post-training quantize the TensorFlow Lite model\n",
        "\n",
        "You can combine pruning with other optimization techniques like post training quantization. As a recap, post-training quantization converts weights to 8 bit precision as part of model conversion from keras model to TFLite's flat buffer, resulting in a 4x reduction in the model size.\n",
        "\n",
        "In the following example, we take the pruned keras model, convert it with post-training quantization, check the size reduction and validate its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wbTNqf1KER0z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6ccda750-5859-41eb-d38e-46229018d329"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model_file(pruned_keras_file)\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "tflite_quant_model_file = '/tmp/sparse_mnist_quant.tflite'\n",
        "with open(tflite_quant_model_file, 'wb') as f:\n",
        "  f.write(tflite_quant_model)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "INFO:tensorflow:Converted 12 variables to const ops.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s6a8bH_-EXeR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c6823dc8-2d5c-4b92-ae77-f0de1e152e6b"
      },
      "source": [
        "_, zip_tflite = tempfile.mkstemp('.zip')\n",
        "with zipfile.ZipFile(zip_tflite, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "  f.write(tflite_quant_model_file)\n",
        "print(\"Size of the tflite model before compression: %.2f Mb\" \n",
        "      % (os.path.getsize(tflite_quant_model_file) / float(2**20)))\n",
        "print(\"Size of the tflite model after compression: %.2f Mb\" \n",
        "      % (os.path.getsize(zip_tflite) / float(2**20)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the tflite model before compression: 3.13 Mb\n",
            "Size of the tflite model after compression: 0.58 Mb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lMuuxZs_QxMt"
      },
      "source": [
        "The size of the quantized model is roughly 1/4 of the orignial one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dkv9mauCEami",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e089a7a6-7d6b-4b9e-cd3b-32b20f0d8559"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=str(tflite_quant_model_file))\n",
        "interpreter.allocate_tensors()\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "print(eval_model(interpreter, x_test, y_test))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy after 1000 images: 0.993000\n",
            "Accuracy after 2000 images: 0.990000\n",
            "Accuracy after 3000 images: 0.989000\n",
            "Accuracy after 4000 images: 0.990250\n",
            "Accuracy after 5000 images: 0.990600\n",
            "Accuracy after 6000 images: 0.991167\n",
            "Accuracy after 7000 images: 0.991857\n",
            "Accuracy after 8000 images: 0.992875\n",
            "Accuracy after 9000 images: 0.993444\n",
            "Accuracy after 10000 images: 0.993300\n",
            "0.9933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ygzK3KZcoZ-w"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this tutorial, we showed you how to create *sparse models* with the TensorFlow model optimization toolkit weight pruning API. Right now, this allows you to create models that take significant less space on disk. The resulting model can also be more efficiently implemented to avoid computation; in the future TensorFlow Lite will provide such capabilities.\n",
        "\n",
        "More specifically, we walked you through an end-to-end example of training a simple MNIST model that used the weight pruning API. We showed you how to convert it to the Tensorflow Lite format for mobile deployment, and demonstrated how with simple file compression the model size was reduced 5x.\n",
        "\n",
        "We encourage you to try this new capability on your Keras models, which can be particularly important for deployment in resource-constraint environments. \n",
        "\n"
      ]
    }
  ]
}